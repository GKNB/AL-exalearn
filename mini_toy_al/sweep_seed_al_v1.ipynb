{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16a891b2-5bf4-45ed-a175-e89c79a105b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "\n",
    "print(torch.get_num_threads())\n",
    "print(torch.get_num_interop_threads())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa3175cd-9863-4530-b3ec-09203e7eacfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_orig = np.arange(-2.4, 2.8, 0.4)\n",
    "#x_train_orig = np.arange(-2.4, 2.6, 0.2)\n",
    "#x_train_orig = np.arange(-2.4, 2.5, 0.1)\n",
    "#x_train_orig = np.arange(-2.4, 2.45, 0.05)\n",
    "x_train_orig = np.arange(-2.4, 2.425, 0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c5e2f97-a8df-4aef-b57b-715a8abe8319",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FullModel, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(1, 8)\n",
    "        self.fc2 = torch.nn.Linear(8, 8)\n",
    "        self.fc3 = torch.nn.Linear(8, 1)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a03d9c4b-45a5-4562-9587-4e5bc133fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    x = x.astype(float)\n",
    "    return np.power(x, 1) * np.power(np.sin(1.0 / 3.0 * x), 2)\n",
    "\n",
    "def avg_l2_diff(y1, y2):\n",
    "    return np.average(np.power(y1-y2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0e80481-5b5b-49db-933c-65e6bb0e63ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    running_loss  = torch.tensor(0.0)\n",
    "\n",
    "    for batch_idx, current_batch in enumerate(train_loader):     \n",
    "        inp, current_batch_y = current_batch[0],        current_batch[1]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(inp)\n",
    "        gndtruth = current_batch_y\n",
    "\n",
    "        loss = criterion(output, gndtruth)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss  += loss.item()\n",
    "\n",
    "    running_loss  = running_loss  / len(train_loader)\n",
    "    \n",
    "    if epoch % 40 == 0:\n",
    "        print(\"Epoch: {}, Average loss: {:15.8f}\".format(epoch, running_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85bd42da-9c23-44f7-96ac-642a5112818a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orig train size =  193\n",
      "Epoch: 40, Average loss:      0.00075523\n",
      "Epoch: 80, Average loss:      0.00054278\n",
      "Epoch: 120, Average loss:      0.00044488\n",
      "Epoch: 160, Average loss:      0.00036991\n",
      "Epoch: 200, Average loss:      0.00032052\n",
      "Epoch: 240, Average loss:      0.00026815\n",
      "Epoch: 280, Average loss:      0.00023101\n",
      "Epoch: 320, Average loss:      0.00021171\n",
      "Epoch: 360, Average loss:      0.00020731\n",
      "Epoch: 400, Average loss:      0.00018216\n",
      "Epoch: 440, Average loss:      0.00018216\n",
      "Epoch: 480, Average loss:      0.00017778\n",
      "Epoch: 520, Average loss:      0.00016917\n",
      "Epoch: 560, Average loss:      0.00016065\n",
      "Epoch: 600, Average loss:      0.00014675\n",
      "Epoch: 640, Average loss:      0.00016595\n",
      "Epoch: 680, Average loss:      0.00015850\n",
      "Epoch: 720, Average loss:      0.00014632\n",
      "Epoch: 760, Average loss:      0.00015157\n",
      "Epoch: 800, Average loss:      0.00014502\n",
      "Epoch: 840, Average loss:      0.00014595\n",
      "Epoch: 880, Average loss:      0.00013983\n",
      "Epoch: 920, Average loss:      0.00013640\n",
      "Epoch: 960, Average loss:      0.00013028\n",
      "Epoch: 1000, Average loss:      0.00011862\n",
      "Epoch: 1040, Average loss:      0.00013493\n",
      "Epoch: 1080, Average loss:      0.00012031\n",
      "Epoch: 1120, Average loss:      0.00012044\n",
      "Epoch: 1160, Average loss:      0.00011519\n",
      "Epoch: 1200, Average loss:      0.00011966\n",
      "Epoch: 1240, Average loss:      0.00011725\n",
      "Epoch: 1280, Average loss:      0.00011753\n",
      "Epoch: 1320, Average loss:      0.00010096\n",
      "Epoch: 1360, Average loss:      0.00010382\n",
      "Epoch: 1400, Average loss:      0.00010418\n",
      "Epoch: 1440, Average loss:      0.00009637\n",
      "Epoch: 1480, Average loss:      0.00009868\n",
      "Epoch: 1520, Average loss:      0.00009691\n",
      "Epoch: 1560, Average loss:      0.00009078\n",
      "Epoch: 1600, Average loss:      0.00008779\n",
      "Epoch: 1640, Average loss:      0.00008919\n",
      "Epoch: 1680, Average loss:      0.00008248\n",
      "Epoch: 1720, Average loss:      0.00008576\n",
      "Epoch: 1760, Average loss:      0.00008455\n",
      "Epoch: 1800, Average loss:      0.00008563\n",
      "Epoch: 1840, Average loss:      0.00008197\n",
      "Epoch: 1880, Average loss:      0.00008005\n",
      "Epoch: 1920, Average loss:      0.00007672\n",
      "Epoch: 1960, Average loss:      0.00007588\n",
      "Orig train size =  193\n",
      "Epoch: 40, Average loss:      0.00103376\n",
      "Epoch: 80, Average loss:      0.00032878\n",
      "Epoch: 120, Average loss:      0.00020988\n",
      "Epoch: 160, Average loss:      0.00015738\n",
      "Epoch: 200, Average loss:      0.00014602\n",
      "Epoch: 240, Average loss:      0.00013755\n",
      "Epoch: 280, Average loss:      0.00012518\n",
      "Epoch: 320, Average loss:      0.00011178\n",
      "Epoch: 360, Average loss:      0.00010807\n",
      "Epoch: 400, Average loss:      0.00010624\n",
      "Epoch: 440, Average loss:      0.00009760\n",
      "Epoch: 480, Average loss:      0.00008734\n",
      "Epoch: 520, Average loss:      0.00009038\n",
      "Epoch: 560, Average loss:      0.00008777\n",
      "Epoch: 600, Average loss:      0.00007847\n",
      "Epoch: 640, Average loss:      0.00008364\n",
      "Epoch: 680, Average loss:      0.00007251\n",
      "Epoch: 720, Average loss:      0.00007488\n",
      "Epoch: 760, Average loss:      0.00006643\n",
      "Epoch: 800, Average loss:      0.00006772\n",
      "Epoch: 840, Average loss:      0.00007326\n",
      "Epoch: 880, Average loss:      0.00006035\n",
      "Epoch: 920, Average loss:      0.00006159\n",
      "Epoch: 960, Average loss:      0.00005970\n",
      "Epoch: 1000, Average loss:      0.00006356\n",
      "Epoch: 1040, Average loss:      0.00005762\n",
      "Epoch: 1080, Average loss:      0.00006017\n",
      "Epoch: 1120, Average loss:      0.00005418\n",
      "Epoch: 1160, Average loss:      0.00004843\n",
      "Epoch: 1200, Average loss:      0.00004923\n",
      "Epoch: 1240, Average loss:      0.00005109\n",
      "Epoch: 1280, Average loss:      0.00004387\n",
      "Epoch: 1320, Average loss:      0.00004612\n",
      "Epoch: 1360, Average loss:      0.00004293\n",
      "Epoch: 1400, Average loss:      0.00004811\n",
      "Epoch: 1440, Average loss:      0.00004620\n",
      "Epoch: 1480, Average loss:      0.00004539\n",
      "Epoch: 1520, Average loss:      0.00003962\n",
      "Epoch: 1560, Average loss:      0.00003633\n",
      "Epoch: 1600, Average loss:      0.00004098\n",
      "Epoch: 1640, Average loss:      0.00003649\n",
      "Epoch: 1680, Average loss:      0.00003759\n",
      "Epoch: 1720, Average loss:      0.00003554\n",
      "Epoch: 1760, Average loss:      0.00003440\n",
      "Epoch: 1800, Average loss:      0.00003537\n",
      "Epoch: 1840, Average loss:      0.00003167\n",
      "Epoch: 1880, Average loss:      0.00003549\n",
      "Epoch: 1920, Average loss:      0.00003486\n",
      "Epoch: 1960, Average loss:      0.00003467\n",
      "Orig train size =  193\n",
      "Epoch: 40, Average loss:      0.00081875\n",
      "Epoch: 80, Average loss:      0.00049725\n",
      "Epoch: 120, Average loss:      0.00043345\n",
      "Epoch: 160, Average loss:      0.00032828\n",
      "Epoch: 200, Average loss:      0.00025781\n",
      "Epoch: 240, Average loss:      0.00024266\n",
      "Epoch: 280, Average loss:      0.00019440\n",
      "Epoch: 320, Average loss:      0.00022117\n",
      "Epoch: 360, Average loss:      0.00019359\n",
      "Epoch: 400, Average loss:      0.00017300\n",
      "Epoch: 440, Average loss:      0.00014756\n",
      "Epoch: 480, Average loss:      0.00016286\n",
      "Epoch: 520, Average loss:      0.00014345\n",
      "Epoch: 560, Average loss:      0.00014111\n",
      "Epoch: 600, Average loss:      0.00014372\n",
      "Epoch: 640, Average loss:      0.00014937\n",
      "Epoch: 680, Average loss:      0.00013926\n",
      "Epoch: 720, Average loss:      0.00014833\n",
      "Epoch: 760, Average loss:      0.00014019\n",
      "Epoch: 800, Average loss:      0.00012673\n",
      "Epoch: 840, Average loss:      0.00012504\n",
      "Epoch: 880, Average loss:      0.00012261\n",
      "Epoch: 920, Average loss:      0.00011525\n",
      "Epoch: 960, Average loss:      0.00011859\n",
      "Epoch: 1000, Average loss:      0.00013177\n",
      "Epoch: 1040, Average loss:      0.00011773\n",
      "Epoch: 1080, Average loss:      0.00009781\n",
      "Epoch: 1120, Average loss:      0.00010684\n",
      "Epoch: 1160, Average loss:      0.00011178\n",
      "Epoch: 1200, Average loss:      0.00012172\n",
      "Epoch: 1240, Average loss:      0.00010574\n",
      "Epoch: 1280, Average loss:      0.00011114\n",
      "Epoch: 1320, Average loss:      0.00011036\n",
      "Epoch: 1360, Average loss:      0.00010455\n",
      "Epoch: 1400, Average loss:      0.00010327\n",
      "Epoch: 1440, Average loss:      0.00010353\n",
      "Epoch: 1480, Average loss:      0.00009696\n",
      "Epoch: 1520, Average loss:      0.00008510\n",
      "Epoch: 1560, Average loss:      0.00009861\n",
      "Epoch: 1600, Average loss:      0.00009859\n",
      "Epoch: 1640, Average loss:      0.00008998\n",
      "Epoch: 1680, Average loss:      0.00007942\n",
      "Epoch: 1720, Average loss:      0.00009806\n",
      "Epoch: 1760, Average loss:      0.00009587\n",
      "Epoch: 1800, Average loss:      0.00008855\n",
      "Epoch: 1840, Average loss:      0.00009541\n",
      "Epoch: 1880, Average loss:      0.00009804\n",
      "Epoch: 1920, Average loss:      0.00009162\n",
      "Epoch: 1960, Average loss:      0.00009209\n",
      "Orig train size =  193\n",
      "Epoch: 40, Average loss:      0.00041058\n",
      "Epoch: 80, Average loss:      0.00025646\n",
      "Epoch: 120, Average loss:      0.00019239\n",
      "Epoch: 160, Average loss:      0.00016622\n",
      "Epoch: 200, Average loss:      0.00016142\n",
      "Epoch: 240, Average loss:      0.00014563\n",
      "Epoch: 280, Average loss:      0.00011912\n",
      "Epoch: 320, Average loss:      0.00012821\n",
      "Epoch: 360, Average loss:      0.00012084\n",
      "Epoch: 400, Average loss:      0.00011158\n",
      "Epoch: 440, Average loss:      0.00011907\n",
      "Epoch: 480, Average loss:      0.00012208\n",
      "Epoch: 520, Average loss:      0.00009659\n",
      "Epoch: 560, Average loss:      0.00008549\n",
      "Epoch: 600, Average loss:      0.00008811\n",
      "Epoch: 640, Average loss:      0.00009137\n",
      "Epoch: 680, Average loss:      0.00008760\n",
      "Epoch: 720, Average loss:      0.00007121\n",
      "Epoch: 760, Average loss:      0.00007706\n",
      "Epoch: 800, Average loss:      0.00007686\n",
      "Epoch: 840, Average loss:      0.00006746\n",
      "Epoch: 880, Average loss:      0.00007633\n",
      "Epoch: 920, Average loss:      0.00007457\n",
      "Epoch: 960, Average loss:      0.00006423\n",
      "Epoch: 1000, Average loss:      0.00007258\n",
      "Epoch: 1040, Average loss:      0.00007114\n",
      "Epoch: 1080, Average loss:      0.00005998\n",
      "Epoch: 1120, Average loss:      0.00005886\n",
      "Epoch: 1160, Average loss:      0.00006559\n",
      "Epoch: 1200, Average loss:      0.00006220\n",
      "Epoch: 1240, Average loss:      0.00006023\n",
      "Epoch: 1280, Average loss:      0.00005706\n",
      "Epoch: 1320, Average loss:      0.00005389\n",
      "Epoch: 1360, Average loss:      0.00005778\n",
      "Epoch: 1400, Average loss:      0.00006042\n",
      "Epoch: 1440, Average loss:      0.00005314\n",
      "Epoch: 1480, Average loss:      0.00005917\n",
      "Epoch: 1520, Average loss:      0.00005597\n",
      "Epoch: 1560, Average loss:      0.00004790\n",
      "Epoch: 1600, Average loss:      0.00005271\n",
      "Epoch: 1640, Average loss:      0.00005287\n",
      "Epoch: 1680, Average loss:      0.00004885\n",
      "Epoch: 1720, Average loss:      0.00005176\n",
      "Epoch: 1760, Average loss:      0.00005539\n",
      "Epoch: 1800, Average loss:      0.00005239\n",
      "Epoch: 1840, Average loss:      0.00005325\n",
      "Epoch: 1880, Average loss:      0.00005161\n",
      "Epoch: 1920, Average loss:      0.00005791\n",
      "Epoch: 1960, Average loss:      0.00005330\n",
      "Orig train size =  193\n",
      "Epoch: 40, Average loss:      0.00052407\n",
      "Epoch: 80, Average loss:      0.00034556\n",
      "Epoch: 120, Average loss:      0.00029272\n",
      "Epoch: 160, Average loss:      0.00026890\n",
      "Epoch: 200, Average loss:      0.00022343\n",
      "Epoch: 240, Average loss:      0.00021486\n",
      "Epoch: 280, Average loss:      0.00019868\n",
      "Epoch: 320, Average loss:      0.00018449\n",
      "Epoch: 360, Average loss:      0.00017398\n",
      "Epoch: 400, Average loss:      0.00017513\n",
      "Epoch: 440, Average loss:      0.00019339\n",
      "Epoch: 480, Average loss:      0.00016871\n",
      "Epoch: 520, Average loss:      0.00016879\n",
      "Epoch: 560, Average loss:      0.00016977\n",
      "Epoch: 600, Average loss:      0.00016779\n",
      "Epoch: 640, Average loss:      0.00014969\n",
      "Epoch: 680, Average loss:      0.00013142\n",
      "Epoch: 720, Average loss:      0.00014785\n",
      "Epoch: 760, Average loss:      0.00014043\n",
      "Epoch: 800, Average loss:      0.00013670\n",
      "Epoch: 840, Average loss:      0.00012451\n",
      "Epoch: 880, Average loss:      0.00011942\n",
      "Epoch: 920, Average loss:      0.00012080\n",
      "Epoch: 960, Average loss:      0.00010310\n",
      "Epoch: 1000, Average loss:      0.00011810\n",
      "Epoch: 1040, Average loss:      0.00012334\n",
      "Epoch: 1080, Average loss:      0.00011111\n",
      "Epoch: 1120, Average loss:      0.00011266\n",
      "Epoch: 1160, Average loss:      0.00011198\n",
      "Epoch: 1200, Average loss:      0.00009932\n",
      "Epoch: 1240, Average loss:      0.00011037\n",
      "Epoch: 1280, Average loss:      0.00009581\n",
      "Epoch: 1320, Average loss:      0.00010554\n",
      "Epoch: 1360, Average loss:      0.00009413\n",
      "Epoch: 1400, Average loss:      0.00010856\n",
      "Epoch: 1440, Average loss:      0.00010545\n",
      "Epoch: 1480, Average loss:      0.00010147\n",
      "Epoch: 1520, Average loss:      0.00010063\n",
      "Epoch: 1560, Average loss:      0.00010280\n",
      "Epoch: 1600, Average loss:      0.00008697\n",
      "Epoch: 1640, Average loss:      0.00010197\n",
      "Epoch: 1680, Average loss:      0.00009210\n",
      "Epoch: 1720, Average loss:      0.00009882\n",
      "Epoch: 1760, Average loss:      0.00008668\n",
      "Epoch: 1800, Average loss:      0.00009544\n",
      "Epoch: 1840, Average loss:      0.00009095\n",
      "Epoch: 1880, Average loss:      0.00009675\n",
      "Epoch: 1920, Average loss:      0.00008313\n",
      "Epoch: 1960, Average loss:      0.00008899\n",
      "Orig train size =  193\n",
      "Epoch: 40, Average loss:      0.00059086\n",
      "Epoch: 80, Average loss:      0.00031010\n",
      "Epoch: 120, Average loss:      0.00029092\n",
      "Epoch: 160, Average loss:      0.00023745\n",
      "Epoch: 200, Average loss:      0.00023351\n",
      "Epoch: 240, Average loss:      0.00024888\n",
      "Epoch: 280, Average loss:      0.00020326\n",
      "Epoch: 320, Average loss:      0.00021903\n",
      "Epoch: 360, Average loss:      0.00021760\n",
      "Epoch: 400, Average loss:      0.00023448\n",
      "Epoch: 440, Average loss:      0.00019232\n",
      "Epoch: 480, Average loss:      0.00020073\n",
      "Epoch: 520, Average loss:      0.00018848\n",
      "Epoch: 560, Average loss:      0.00016887\n",
      "Epoch: 600, Average loss:      0.00018071\n",
      "Epoch: 640, Average loss:      0.00016626\n",
      "Epoch: 680, Average loss:      0.00019745\n",
      "Epoch: 720, Average loss:      0.00017376\n",
      "Epoch: 760, Average loss:      0.00015998\n",
      "Epoch: 800, Average loss:      0.00015283\n",
      "Epoch: 840, Average loss:      0.00015385\n",
      "Epoch: 880, Average loss:      0.00014533\n",
      "Epoch: 920, Average loss:      0.00015218\n",
      "Epoch: 960, Average loss:      0.00013447\n",
      "Epoch: 1000, Average loss:      0.00012332\n",
      "Epoch: 1040, Average loss:      0.00014224\n",
      "Epoch: 1080, Average loss:      0.00013627\n",
      "Epoch: 1120, Average loss:      0.00011501\n",
      "Epoch: 1160, Average loss:      0.00013668\n",
      "Epoch: 1200, Average loss:      0.00012565\n",
      "Epoch: 1240, Average loss:      0.00010237\n",
      "Epoch: 1280, Average loss:      0.00011374\n",
      "Epoch: 1320, Average loss:      0.00011471\n",
      "Epoch: 1360, Average loss:      0.00011388\n",
      "Epoch: 1400, Average loss:      0.00009885\n",
      "Epoch: 1440, Average loss:      0.00009801\n",
      "Epoch: 1480, Average loss:      0.00010673\n",
      "Epoch: 1520, Average loss:      0.00010722\n",
      "Epoch: 1560, Average loss:      0.00009448\n",
      "Epoch: 1600, Average loss:      0.00010828\n",
      "Epoch: 1640, Average loss:      0.00008418\n",
      "Epoch: 1680, Average loss:      0.00009329\n",
      "Epoch: 1720, Average loss:      0.00009403\n",
      "Epoch: 1760, Average loss:      0.00008820\n",
      "Epoch: 1800, Average loss:      0.00009122\n",
      "Epoch: 1840, Average loss:      0.00008010\n",
      "Epoch: 1880, Average loss:      0.00008319\n",
      "Epoch: 1920, Average loss:      0.00008485\n",
      "Epoch: 1960, Average loss:      0.00008991\n",
      "Orig train size =  193\n",
      "Epoch: 40, Average loss:      0.00090418\n",
      "Epoch: 80, Average loss:      0.00082995\n",
      "Epoch: 120, Average loss:      0.00069161\n",
      "Epoch: 160, Average loss:      0.00064218\n",
      "Epoch: 200, Average loss:      0.00055442\n",
      "Epoch: 240, Average loss:      0.00050686\n",
      "Epoch: 280, Average loss:      0.00045379\n",
      "Epoch: 320, Average loss:      0.00037760\n",
      "Epoch: 360, Average loss:      0.00033407\n",
      "Epoch: 400, Average loss:      0.00029551\n",
      "Epoch: 440, Average loss:      0.00026040\n",
      "Epoch: 480, Average loss:      0.00024972\n",
      "Epoch: 520, Average loss:      0.00023734\n",
      "Epoch: 560, Average loss:      0.00021994\n",
      "Epoch: 600, Average loss:      0.00019349\n",
      "Epoch: 640, Average loss:      0.00021323\n",
      "Epoch: 680, Average loss:      0.00018249\n",
      "Epoch: 720, Average loss:      0.00019308\n",
      "Epoch: 760, Average loss:      0.00017730\n",
      "Epoch: 800, Average loss:      0.00017395\n",
      "Epoch: 840, Average loss:      0.00017989\n",
      "Epoch: 880, Average loss:      0.00017089\n",
      "Epoch: 920, Average loss:      0.00017521\n",
      "Epoch: 960, Average loss:      0.00015835\n",
      "Epoch: 1000, Average loss:      0.00017520\n",
      "Epoch: 1040, Average loss:      0.00018268\n",
      "Epoch: 1080, Average loss:      0.00016833\n",
      "Epoch: 1120, Average loss:      0.00016954\n",
      "Epoch: 1160, Average loss:      0.00018386\n",
      "Epoch: 1200, Average loss:      0.00015655\n",
      "Epoch: 1240, Average loss:      0.00017240\n",
      "Epoch: 1280, Average loss:      0.00016685\n",
      "Epoch: 1320, Average loss:      0.00017934\n",
      "Epoch: 1360, Average loss:      0.00017134\n",
      "Epoch: 1400, Average loss:      0.00017380\n",
      "Epoch: 1440, Average loss:      0.00016266\n",
      "Epoch: 1480, Average loss:      0.00017586\n",
      "Epoch: 1520, Average loss:      0.00015591\n",
      "Epoch: 1560, Average loss:      0.00017234\n",
      "Epoch: 1600, Average loss:      0.00018286\n",
      "Epoch: 1640, Average loss:      0.00017486\n",
      "Epoch: 1680, Average loss:      0.00016131\n",
      "Epoch: 1720, Average loss:      0.00016352\n",
      "Epoch: 1760, Average loss:      0.00016204\n",
      "Epoch: 1800, Average loss:      0.00016883\n",
      "Epoch: 1840, Average loss:      0.00015884\n",
      "Epoch: 1880, Average loss:      0.00015742\n",
      "Epoch: 1920, Average loss:      0.00015611\n",
      "Epoch: 1960, Average loss:      0.00015590\n",
      "Orig train size =  193\n",
      "Epoch: 40, Average loss:      0.00039919\n",
      "Epoch: 80, Average loss:      0.00025846\n",
      "Epoch: 120, Average loss:      0.00023651\n",
      "Epoch: 160, Average loss:      0.00022683\n",
      "Epoch: 200, Average loss:      0.00021112\n",
      "Epoch: 240, Average loss:      0.00019723\n",
      "Epoch: 280, Average loss:      0.00018669\n",
      "Epoch: 320, Average loss:      0.00019809\n",
      "Epoch: 360, Average loss:      0.00018920\n",
      "Epoch: 400, Average loss:      0.00018145\n",
      "Epoch: 440, Average loss:      0.00017798\n",
      "Epoch: 480, Average loss:      0.00020135\n",
      "Epoch: 520, Average loss:      0.00017357\n",
      "Epoch: 560, Average loss:      0.00019318\n",
      "Epoch: 600, Average loss:      0.00017323\n",
      "Epoch: 640, Average loss:      0.00017840\n",
      "Epoch: 680, Average loss:      0.00015438\n",
      "Epoch: 720, Average loss:      0.00017869\n",
      "Epoch: 760, Average loss:      0.00018155\n",
      "Epoch: 800, Average loss:      0.00018314\n",
      "Epoch: 840, Average loss:      0.00017803\n",
      "Epoch: 880, Average loss:      0.00016844\n",
      "Epoch: 920, Average loss:      0.00015140\n",
      "Epoch: 960, Average loss:      0.00017031\n",
      "Epoch: 1000, Average loss:      0.00016364\n",
      "Epoch: 1040, Average loss:      0.00016870\n",
      "Epoch: 1080, Average loss:      0.00015682\n",
      "Epoch: 1120, Average loss:      0.00015870\n",
      "Epoch: 1160, Average loss:      0.00014580\n",
      "Epoch: 1200, Average loss:      0.00016630\n",
      "Epoch: 1240, Average loss:      0.00015620\n",
      "Epoch: 1280, Average loss:      0.00014535\n",
      "Epoch: 1320, Average loss:      0.00014123\n",
      "Epoch: 1360, Average loss:      0.00014499\n",
      "Epoch: 1400, Average loss:      0.00017487\n",
      "Epoch: 1440, Average loss:      0.00015326\n",
      "Epoch: 1480, Average loss:      0.00015658\n",
      "Epoch: 1520, Average loss:      0.00016810\n",
      "Epoch: 1560, Average loss:      0.00016651\n",
      "Epoch: 1600, Average loss:      0.00015862\n",
      "Epoch: 1640, Average loss:      0.00014657\n",
      "Epoch: 1680, Average loss:      0.00015924\n",
      "Epoch: 1720, Average loss:      0.00014491\n",
      "Epoch: 1760, Average loss:      0.00014376\n",
      "Epoch: 1800, Average loss:      0.00015351\n",
      "Epoch: 1840, Average loss:      0.00016130\n",
      "Epoch: 1880, Average loss:      0.00015973\n",
      "Epoch: 1920, Average loss:      0.00015059\n",
      "Epoch: 1960, Average loss:      0.00013943\n",
      "Orig train size =  193\n",
      "Epoch: 40, Average loss:      0.00065301\n",
      "Epoch: 80, Average loss:      0.00029817\n",
      "Epoch: 120, Average loss:      0.00022406\n",
      "Epoch: 160, Average loss:      0.00017358\n",
      "Epoch: 200, Average loss:      0.00016239\n",
      "Epoch: 240, Average loss:      0.00015715\n",
      "Epoch: 280, Average loss:      0.00012739\n",
      "Epoch: 320, Average loss:      0.00014972\n",
      "Epoch: 360, Average loss:      0.00011160\n",
      "Epoch: 400, Average loss:      0.00012053\n",
      "Epoch: 440, Average loss:      0.00010966\n",
      "Epoch: 480, Average loss:      0.00011342\n",
      "Epoch: 520, Average loss:      0.00010717\n",
      "Epoch: 560, Average loss:      0.00010360\n",
      "Epoch: 600, Average loss:      0.00008967\n",
      "Epoch: 640, Average loss:      0.00008544\n",
      "Epoch: 680, Average loss:      0.00008951\n",
      "Epoch: 720, Average loss:      0.00008049\n",
      "Epoch: 760, Average loss:      0.00009027\n",
      "Epoch: 800, Average loss:      0.00008528\n",
      "Epoch: 840, Average loss:      0.00007556\n",
      "Epoch: 880, Average loss:      0.00006495\n",
      "Epoch: 920, Average loss:      0.00006367\n",
      "Epoch: 960, Average loss:      0.00006778\n",
      "Epoch: 1000, Average loss:      0.00006999\n",
      "Epoch: 1040, Average loss:      0.00006899\n",
      "Epoch: 1080, Average loss:      0.00007127\n",
      "Epoch: 1120, Average loss:      0.00005873\n",
      "Epoch: 1160, Average loss:      0.00006010\n",
      "Epoch: 1200, Average loss:      0.00005616\n",
      "Epoch: 1240, Average loss:      0.00006671\n",
      "Epoch: 1280, Average loss:      0.00006581\n",
      "Epoch: 1320, Average loss:      0.00005607\n",
      "Epoch: 1360, Average loss:      0.00005903\n",
      "Epoch: 1400, Average loss:      0.00005735\n",
      "Epoch: 1440, Average loss:      0.00005127\n",
      "Epoch: 1480, Average loss:      0.00005448\n",
      "Epoch: 1520, Average loss:      0.00006181\n",
      "Epoch: 1560, Average loss:      0.00006214\n",
      "Epoch: 1600, Average loss:      0.00005841\n",
      "Epoch: 1640, Average loss:      0.00005370\n",
      "Epoch: 1680, Average loss:      0.00005595\n",
      "Epoch: 1720, Average loss:      0.00005833\n",
      "Epoch: 1760, Average loss:      0.00005153\n",
      "Epoch: 1800, Average loss:      0.00005522\n",
      "Epoch: 1840, Average loss:      0.00005602\n",
      "Epoch: 1880, Average loss:      0.00006002\n",
      "Epoch: 1920, Average loss:      0.00005807\n",
      "Epoch: 1960, Average loss:      0.00005070\n",
      "Orig train size =  193\n",
      "Epoch: 40, Average loss:      0.00049248\n",
      "Epoch: 80, Average loss:      0.00025493\n",
      "Epoch: 120, Average loss:      0.00019097\n",
      "Epoch: 160, Average loss:      0.00015467\n",
      "Epoch: 200, Average loss:      0.00014764\n",
      "Epoch: 240, Average loss:      0.00012946\n",
      "Epoch: 280, Average loss:      0.00010812\n",
      "Epoch: 320, Average loss:      0.00010570\n",
      "Epoch: 360, Average loss:      0.00010564\n",
      "Epoch: 400, Average loss:      0.00009831\n",
      "Epoch: 440, Average loss:      0.00009018\n",
      "Epoch: 480, Average loss:      0.00008804\n",
      "Epoch: 520, Average loss:      0.00008195\n",
      "Epoch: 560, Average loss:      0.00007144\n",
      "Epoch: 600, Average loss:      0.00007677\n",
      "Epoch: 640, Average loss:      0.00007304\n",
      "Epoch: 680, Average loss:      0.00006904\n",
      "Epoch: 720, Average loss:      0.00006764\n",
      "Epoch: 760, Average loss:      0.00007569\n",
      "Epoch: 800, Average loss:      0.00006298\n",
      "Epoch: 840, Average loss:      0.00005857\n",
      "Epoch: 880, Average loss:      0.00005871\n",
      "Epoch: 920, Average loss:      0.00005743\n",
      "Epoch: 960, Average loss:      0.00005444\n",
      "Epoch: 1000, Average loss:      0.00005606\n",
      "Epoch: 1040, Average loss:      0.00004905\n",
      "Epoch: 1080, Average loss:      0.00005440\n",
      "Epoch: 1120, Average loss:      0.00005114\n",
      "Epoch: 1160, Average loss:      0.00005334\n",
      "Epoch: 1200, Average loss:      0.00004862\n",
      "Epoch: 1240, Average loss:      0.00005208\n",
      "Epoch: 1280, Average loss:      0.00005553\n",
      "Epoch: 1320, Average loss:      0.00005006\n",
      "Epoch: 1360, Average loss:      0.00004409\n",
      "Epoch: 1400, Average loss:      0.00004095\n",
      "Epoch: 1440, Average loss:      0.00004540\n",
      "Epoch: 1480, Average loss:      0.00004427\n",
      "Epoch: 1520, Average loss:      0.00004314\n",
      "Epoch: 1560, Average loss:      0.00004573\n",
      "Epoch: 1600, Average loss:      0.00004412\n",
      "Epoch: 1640, Average loss:      0.00004246\n",
      "Epoch: 1680, Average loss:      0.00003455\n",
      "Epoch: 1720, Average loss:      0.00004372\n",
      "Epoch: 1760, Average loss:      0.00003924\n",
      "Epoch: 1800, Average loss:      0.00003769\n",
      "Epoch: 1840, Average loss:      0.00004004\n",
      "Epoch: 1880, Average loss:      0.00003515\n",
      "Epoch: 1920, Average loss:      0.00003260\n",
      "Epoch: 1960, Average loss:      0.00003233\n",
      "Orig train size =  193\n",
      "Epoch: 40, Average loss:      0.00147867\n",
      "Epoch: 80, Average loss:      0.00091306\n",
      "Epoch: 120, Average loss:      0.00065651\n",
      "Epoch: 160, Average loss:      0.00062943\n",
      "Epoch: 200, Average loss:      0.00053073\n",
      "Epoch: 240, Average loss:      0.00040664\n",
      "Epoch: 280, Average loss:      0.00034555\n",
      "Epoch: 320, Average loss:      0.00027309\n",
      "Epoch: 360, Average loss:      0.00028923\n",
      "Epoch: 400, Average loss:      0.00024050\n",
      "Epoch: 440, Average loss:      0.00024265\n",
      "Epoch: 480, Average loss:      0.00020534\n",
      "Epoch: 520, Average loss:      0.00021088\n",
      "Epoch: 560, Average loss:      0.00020951\n",
      "Epoch: 600, Average loss:      0.00018932\n",
      "Epoch: 640, Average loss:      0.00019162\n",
      "Epoch: 680, Average loss:      0.00017667\n",
      "Epoch: 720, Average loss:      0.00017722\n",
      "Epoch: 760, Average loss:      0.00019416\n",
      "Epoch: 800, Average loss:      0.00016092\n",
      "Epoch: 840, Average loss:      0.00020514\n",
      "Epoch: 880, Average loss:      0.00016823\n",
      "Epoch: 920, Average loss:      0.00016410\n",
      "Epoch: 960, Average loss:      0.00016114\n",
      "Epoch: 1000, Average loss:      0.00014991\n",
      "Epoch: 1040, Average loss:      0.00017098\n",
      "Epoch: 1080, Average loss:      0.00016767\n",
      "Epoch: 1120, Average loss:      0.00018058\n",
      "Epoch: 1160, Average loss:      0.00017402\n",
      "Epoch: 1200, Average loss:      0.00016011\n",
      "Epoch: 1240, Average loss:      0.00014509\n",
      "Epoch: 1280, Average loss:      0.00018018\n",
      "Epoch: 1320, Average loss:      0.00014883\n",
      "Epoch: 1360, Average loss:      0.00016004\n",
      "Epoch: 1400, Average loss:      0.00016776\n",
      "Epoch: 1440, Average loss:      0.00015664\n",
      "Epoch: 1480, Average loss:      0.00017570\n",
      "Epoch: 1520, Average loss:      0.00014898\n",
      "Epoch: 1560, Average loss:      0.00016228\n",
      "Epoch: 1600, Average loss:      0.00016417\n",
      "Epoch: 1640, Average loss:      0.00014808\n",
      "Epoch: 1680, Average loss:      0.00014888\n",
      "Epoch: 1720, Average loss:      0.00013516\n",
      "Epoch: 1760, Average loss:      0.00014761\n",
      "Epoch: 1800, Average loss:      0.00014857\n",
      "Epoch: 1840, Average loss:      0.00019714\n",
      "Epoch: 1880, Average loss:      0.00014765\n",
      "Epoch: 1920, Average loss:      0.00014340\n",
      "Epoch: 1960, Average loss:      0.00014561\n",
      "Orig train size =  193\n",
      "Epoch: 40, Average loss:      0.00088452\n",
      "Epoch: 80, Average loss:      0.00059400\n",
      "Epoch: 120, Average loss:      0.00046887\n",
      "Epoch: 160, Average loss:      0.00036118\n",
      "Epoch: 200, Average loss:      0.00028502\n",
      "Epoch: 240, Average loss:      0.00023619\n",
      "Epoch: 280, Average loss:      0.00020928\n",
      "Epoch: 320, Average loss:      0.00018780\n",
      "Epoch: 360, Average loss:      0.00016887\n",
      "Epoch: 400, Average loss:      0.00016529\n",
      "Epoch: 440, Average loss:      0.00014705\n",
      "Epoch: 480, Average loss:      0.00015076\n",
      "Epoch: 520, Average loss:      0.00013520\n",
      "Epoch: 560, Average loss:      0.00013394\n",
      "Epoch: 600, Average loss:      0.00013337\n",
      "Epoch: 640, Average loss:      0.00014289\n",
      "Epoch: 680, Average loss:      0.00013638\n",
      "Epoch: 720, Average loss:      0.00013652\n",
      "Epoch: 760, Average loss:      0.00012101\n",
      "Epoch: 800, Average loss:      0.00014285\n",
      "Epoch: 840, Average loss:      0.00011711\n",
      "Epoch: 880, Average loss:      0.00012024\n",
      "Epoch: 920, Average loss:      0.00014167\n",
      "Epoch: 960, Average loss:      0.00012405\n",
      "Epoch: 1000, Average loss:      0.00011853\n",
      "Epoch: 1040, Average loss:      0.00013189\n",
      "Epoch: 1080, Average loss:      0.00012909\n",
      "Epoch: 1120, Average loss:      0.00010955\n",
      "Epoch: 1160, Average loss:      0.00012793\n",
      "Epoch: 1200, Average loss:      0.00011904\n",
      "Epoch: 1240, Average loss:      0.00011717\n",
      "Epoch: 1280, Average loss:      0.00010854\n",
      "Epoch: 1320, Average loss:      0.00010385\n",
      "Epoch: 1360, Average loss:      0.00010417\n",
      "Epoch: 1400, Average loss:      0.00010887\n",
      "Epoch: 1440, Average loss:      0.00010620\n",
      "Epoch: 1480, Average loss:      0.00011443\n",
      "Epoch: 1520, Average loss:      0.00011098\n",
      "Epoch: 1560, Average loss:      0.00009672\n",
      "Epoch: 1600, Average loss:      0.00010315\n",
      "Epoch: 1640, Average loss:      0.00008873\n",
      "Epoch: 1680, Average loss:      0.00009442\n",
      "Epoch: 1720, Average loss:      0.00010207\n",
      "Epoch: 1760, Average loss:      0.00009408\n",
      "Epoch: 1800, Average loss:      0.00009347\n",
      "Epoch: 1840, Average loss:      0.00009685\n",
      "Epoch: 1880, Average loss:      0.00008433\n",
      "Epoch: 1920, Average loss:      0.00009018\n",
      "Epoch: 1960, Average loss:      0.00009829\n",
      "Orig train size =  193\n",
      "Epoch: 40, Average loss:      0.00167561\n",
      "Epoch: 80, Average loss:      0.00129506\n",
      "Epoch: 120, Average loss:      0.00142181\n",
      "Epoch: 160, Average loss:      0.00121490\n",
      "Epoch: 200, Average loss:      0.00133708\n",
      "Epoch: 240, Average loss:      0.00131975\n",
      "Epoch: 280, Average loss:      0.00127982\n",
      "Epoch: 320, Average loss:      0.00128575\n",
      "Epoch: 360, Average loss:      0.00127752\n",
      "Epoch: 400, Average loss:      0.00122071\n",
      "Epoch: 440, Average loss:      0.00115452\n",
      "Epoch: 480, Average loss:      0.00118924\n",
      "Epoch: 520, Average loss:      0.00103487\n",
      "Epoch: 560, Average loss:      0.00120345\n",
      "Epoch: 600, Average loss:      0.00104543\n",
      "Epoch: 640, Average loss:      0.00112622\n",
      "Epoch: 680, Average loss:      0.00110131\n",
      "Epoch: 720, Average loss:      0.00120876\n",
      "Epoch: 760, Average loss:      0.00115625\n",
      "Epoch: 800, Average loss:      0.00118039\n",
      "Epoch: 840, Average loss:      0.00099433\n",
      "Epoch: 880, Average loss:      0.00115127\n",
      "Epoch: 920, Average loss:      0.00122939\n",
      "Epoch: 960, Average loss:      0.00116212\n",
      "Epoch: 1000, Average loss:      0.00108322\n",
      "Epoch: 1040, Average loss:      0.00114379\n",
      "Epoch: 1080, Average loss:      0.00106793\n",
      "Epoch: 1120, Average loss:      0.00120639\n",
      "Epoch: 1160, Average loss:      0.00120602\n",
      "Epoch: 1200, Average loss:      0.00104682\n",
      "Epoch: 1240, Average loss:      0.00109448\n",
      "Epoch: 1280, Average loss:      0.00109111\n",
      "Epoch: 1320, Average loss:      0.00111077\n",
      "Epoch: 1360, Average loss:      0.00109729\n",
      "Epoch: 1400, Average loss:      0.00113571\n",
      "Epoch: 1440, Average loss:      0.00096499\n",
      "Epoch: 1480, Average loss:      0.00095212\n",
      "Epoch: 1520, Average loss:      0.00107897\n",
      "Epoch: 1560, Average loss:      0.00117372\n",
      "Epoch: 1600, Average loss:      0.00112308\n",
      "Epoch: 1640, Average loss:      0.00110599\n",
      "Epoch: 1680, Average loss:      0.00105643\n",
      "Epoch: 1720, Average loss:      0.00107299\n",
      "Epoch: 1760, Average loss:      0.00109098\n",
      "Epoch: 1800, Average loss:      0.00111175\n",
      "Epoch: 1840, Average loss:      0.00108581\n",
      "Epoch: 1880, Average loss:      0.00099808\n",
      "Epoch: 1920, Average loss:      0.00106570\n",
      "Epoch: 1960, Average loss:      0.00117416\n",
      "Orig train size =  193\n",
      "Epoch: 40, Average loss:      0.00114819\n",
      "Epoch: 80, Average loss:      0.00029971\n",
      "Epoch: 120, Average loss:      0.00017441\n",
      "Epoch: 160, Average loss:      0.00011972\n",
      "Epoch: 200, Average loss:      0.00011058\n",
      "Epoch: 240, Average loss:      0.00010990\n",
      "Epoch: 280, Average loss:      0.00008535\n",
      "Epoch: 320, Average loss:      0.00009334\n",
      "Epoch: 360, Average loss:      0.00007484\n",
      "Epoch: 400, Average loss:      0.00007988\n",
      "Epoch: 440, Average loss:      0.00007171\n",
      "Epoch: 480, Average loss:      0.00008201\n",
      "Epoch: 520, Average loss:      0.00007014\n",
      "Epoch: 560, Average loss:      0.00007164\n",
      "Epoch: 600, Average loss:      0.00007197\n",
      "Epoch: 640, Average loss:      0.00006810\n",
      "Epoch: 680, Average loss:      0.00007147\n",
      "Epoch: 720, Average loss:      0.00006044\n",
      "Epoch: 760, Average loss:      0.00006262\n",
      "Epoch: 800, Average loss:      0.00006687\n",
      "Epoch: 840, Average loss:      0.00006261\n",
      "Epoch: 880, Average loss:      0.00006098\n",
      "Epoch: 920, Average loss:      0.00006669\n",
      "Epoch: 960, Average loss:      0.00006064\n",
      "Epoch: 1000, Average loss:      0.00006658\n",
      "Epoch: 1040, Average loss:      0.00006546\n",
      "Epoch: 1080, Average loss:      0.00005756\n",
      "Epoch: 1120, Average loss:      0.00006128\n",
      "Epoch: 1160, Average loss:      0.00005940\n",
      "Epoch: 1200, Average loss:      0.00005794\n",
      "Epoch: 1240, Average loss:      0.00006303\n",
      "Epoch: 1280, Average loss:      0.00005723\n",
      "Epoch: 1320, Average loss:      0.00005854\n",
      "Epoch: 1360, Average loss:      0.00006671\n",
      "Epoch: 1400, Average loss:      0.00006195\n",
      "Epoch: 1440, Average loss:      0.00006931\n",
      "Epoch: 1480, Average loss:      0.00006524\n",
      "Epoch: 1520, Average loss:      0.00004782\n",
      "Epoch: 1560, Average loss:      0.00006394\n",
      "Epoch: 1600, Average loss:      0.00005728\n",
      "Epoch: 1640, Average loss:      0.00005928\n",
      "Epoch: 1680, Average loss:      0.00005782\n",
      "Epoch: 1720, Average loss:      0.00006010\n",
      "Epoch: 1760, Average loss:      0.00006262\n",
      "Epoch: 1800, Average loss:      0.00005784\n",
      "Epoch: 1840, Average loss:      0.00005688\n",
      "Epoch: 1880, Average loss:      0.00005454\n",
      "Epoch: 1920, Average loss:      0.00006078\n",
      "Epoch: 1960, Average loss:      0.00006502\n",
      "Orig train size =  193\n",
      "Epoch: 40, Average loss:      0.00045893\n",
      "Epoch: 80, Average loss:      0.00019654\n",
      "Epoch: 120, Average loss:      0.00014247\n",
      "Epoch: 160, Average loss:      0.00011360\n",
      "Epoch: 200, Average loss:      0.00010878\n",
      "Epoch: 240, Average loss:      0.00010476\n",
      "Epoch: 280, Average loss:      0.00008749\n",
      "Epoch: 320, Average loss:      0.00008774\n",
      "Epoch: 360, Average loss:      0.00008160\n",
      "Epoch: 400, Average loss:      0.00007221\n",
      "Epoch: 440, Average loss:      0.00007497\n",
      "Epoch: 480, Average loss:      0.00007696\n",
      "Epoch: 520, Average loss:      0.00007110\n",
      "Epoch: 560, Average loss:      0.00006378\n",
      "Epoch: 600, Average loss:      0.00006343\n",
      "Epoch: 640, Average loss:      0.00005904\n",
      "Epoch: 680, Average loss:      0.00005605\n",
      "Epoch: 720, Average loss:      0.00006089\n",
      "Epoch: 760, Average loss:      0.00005793\n",
      "Epoch: 800, Average loss:      0.00005861\n",
      "Epoch: 840, Average loss:      0.00005167\n",
      "Epoch: 880, Average loss:      0.00005866\n",
      "Epoch: 920, Average loss:      0.00005170\n",
      "Epoch: 960, Average loss:      0.00005057\n",
      "Epoch: 1000, Average loss:      0.00005236\n",
      "Epoch: 1040, Average loss:      0.00005040\n",
      "Epoch: 1080, Average loss:      0.00004895\n",
      "Epoch: 1120, Average loss:      0.00004888\n",
      "Epoch: 1160, Average loss:      0.00004663\n",
      "Epoch: 1200, Average loss:      0.00004672\n",
      "Epoch: 1240, Average loss:      0.00004503\n",
      "Epoch: 1280, Average loss:      0.00004321\n",
      "Epoch: 1320, Average loss:      0.00004153\n",
      "Epoch: 1360, Average loss:      0.00004615\n",
      "Epoch: 1400, Average loss:      0.00003915\n",
      "Epoch: 1440, Average loss:      0.00004103\n",
      "Epoch: 1480, Average loss:      0.00004053\n",
      "Epoch: 1520, Average loss:      0.00004190\n",
      "Epoch: 1560, Average loss:      0.00004336\n",
      "Epoch: 1600, Average loss:      0.00003833\n",
      "Epoch: 1640, Average loss:      0.00003680\n",
      "Epoch: 1680, Average loss:      0.00003521\n",
      "Epoch: 1720, Average loss:      0.00003762\n",
      "Epoch: 1760, Average loss:      0.00003582\n",
      "Epoch: 1800, Average loss:      0.00003553\n",
      "Epoch: 1840, Average loss:      0.00003721\n",
      "Epoch: 1880, Average loss:      0.00003490\n",
      "Epoch: 1920, Average loss:      0.00003599\n",
      "Epoch: 1960, Average loss:      0.00003547\n",
      "Orig train size =  193\n",
      "Epoch: 40, Average loss:      0.00098815\n",
      "Epoch: 80, Average loss:      0.00082933\n",
      "Epoch: 120, Average loss:      0.00070746\n",
      "Epoch: 160, Average loss:      0.00062752\n",
      "Epoch: 200, Average loss:      0.00051195\n",
      "Epoch: 240, Average loss:      0.00041837\n",
      "Epoch: 280, Average loss:      0.00031496\n",
      "Epoch: 320, Average loss:      0.00030739\n",
      "Epoch: 360, Average loss:      0.00029390\n",
      "Epoch: 400, Average loss:      0.00028998\n",
      "Epoch: 440, Average loss:      0.00027967\n",
      "Epoch: 480, Average loss:      0.00027431\n",
      "Epoch: 520, Average loss:      0.00021552\n",
      "Epoch: 560, Average loss:      0.00025183\n",
      "Epoch: 600, Average loss:      0.00021038\n",
      "Epoch: 640, Average loss:      0.00023780\n",
      "Epoch: 680, Average loss:      0.00024853\n",
      "Epoch: 720, Average loss:      0.00021160\n",
      "Epoch: 760, Average loss:      0.00021358\n",
      "Epoch: 800, Average loss:      0.00020029\n",
      "Epoch: 840, Average loss:      0.00019502\n",
      "Epoch: 880, Average loss:      0.00019813\n",
      "Epoch: 920, Average loss:      0.00021459\n",
      "Epoch: 960, Average loss:      0.00017236\n",
      "Epoch: 1000, Average loss:      0.00017329\n",
      "Epoch: 1040, Average loss:      0.00019420\n",
      "Epoch: 1080, Average loss:      0.00020445\n",
      "Epoch: 1120, Average loss:      0.00021979\n",
      "Epoch: 1160, Average loss:      0.00022156\n",
      "Epoch: 1200, Average loss:      0.00022090\n",
      "Epoch: 1240, Average loss:      0.00017821\n",
      "Epoch: 1280, Average loss:      0.00019453\n",
      "Epoch: 1320, Average loss:      0.00019754\n",
      "Epoch: 1360, Average loss:      0.00017309\n",
      "Epoch: 1400, Average loss:      0.00019579\n",
      "Epoch: 1440, Average loss:      0.00021304\n",
      "Epoch: 1480, Average loss:      0.00018494\n",
      "Epoch: 1520, Average loss:      0.00019317\n",
      "Epoch: 1560, Average loss:      0.00018000\n",
      "Epoch: 1600, Average loss:      0.00019595\n",
      "Epoch: 1640, Average loss:      0.00018930\n",
      "Epoch: 1680, Average loss:      0.00018774\n",
      "Epoch: 1720, Average loss:      0.00019989\n",
      "Epoch: 1760, Average loss:      0.00017803\n",
      "Epoch: 1800, Average loss:      0.00020339\n",
      "Epoch: 1840, Average loss:      0.00020357\n",
      "Epoch: 1880, Average loss:      0.00017793\n",
      "Epoch: 1920, Average loss:      0.00020432\n",
      "Epoch: 1960, Average loss:      0.00017520\n",
      "Orig train size =  193\n",
      "Epoch: 40, Average loss:      0.00035903\n",
      "Epoch: 80, Average loss:      0.00014746\n",
      "Epoch: 120, Average loss:      0.00010368\n",
      "Epoch: 160, Average loss:      0.00008372\n",
      "Epoch: 200, Average loss:      0.00007898\n",
      "Epoch: 240, Average loss:      0.00007925\n",
      "Epoch: 280, Average loss:      0.00007226\n",
      "Epoch: 320, Average loss:      0.00007052\n",
      "Epoch: 360, Average loss:      0.00007034\n",
      "Epoch: 400, Average loss:      0.00006417\n",
      "Epoch: 440, Average loss:      0.00006317\n",
      "Epoch: 480, Average loss:      0.00006116\n",
      "Epoch: 520, Average loss:      0.00005955\n",
      "Epoch: 560, Average loss:      0.00005770\n",
      "Epoch: 600, Average loss:      0.00005944\n",
      "Epoch: 640, Average loss:      0.00005562\n",
      "Epoch: 680, Average loss:      0.00005447\n",
      "Epoch: 720, Average loss:      0.00005256\n",
      "Epoch: 760, Average loss:      0.00005434\n",
      "Epoch: 800, Average loss:      0.00005344\n",
      "Epoch: 840, Average loss:      0.00005257\n",
      "Epoch: 880, Average loss:      0.00005161\n",
      "Epoch: 920, Average loss:      0.00004888\n",
      "Epoch: 960, Average loss:      0.00005012\n",
      "Epoch: 1000, Average loss:      0.00005148\n",
      "Epoch: 1040, Average loss:      0.00004826\n",
      "Epoch: 1080, Average loss:      0.00004827\n",
      "Epoch: 1120, Average loss:      0.00004440\n",
      "Epoch: 1160, Average loss:      0.00004883\n",
      "Epoch: 1200, Average loss:      0.00004625\n",
      "Epoch: 1240, Average loss:      0.00004622\n",
      "Epoch: 1280, Average loss:      0.00004823\n",
      "Epoch: 1320, Average loss:      0.00004750\n",
      "Epoch: 1360, Average loss:      0.00004395\n",
      "Epoch: 1400, Average loss:      0.00004293\n",
      "Epoch: 1440, Average loss:      0.00004371\n",
      "Epoch: 1480, Average loss:      0.00004506\n",
      "Epoch: 1520, Average loss:      0.00004011\n",
      "Epoch: 1560, Average loss:      0.00004375\n",
      "Epoch: 1600, Average loss:      0.00004131\n",
      "Epoch: 1640, Average loss:      0.00004474\n",
      "Epoch: 1680, Average loss:      0.00004377\n",
      "Epoch: 1720, Average loss:      0.00003866\n",
      "Epoch: 1760, Average loss:      0.00004052\n",
      "Epoch: 1800, Average loss:      0.00003977\n",
      "Epoch: 1840, Average loss:      0.00003817\n",
      "Epoch: 1880, Average loss:      0.00003949\n",
      "Epoch: 1920, Average loss:      0.00004097\n",
      "Epoch: 1960, Average loss:      0.00003648\n",
      "Orig train size =  193\n",
      "Epoch: 40, Average loss:      0.00119024\n",
      "Epoch: 80, Average loss:      0.00087852\n",
      "Epoch: 120, Average loss:      0.00070646\n",
      "Epoch: 160, Average loss:      0.00048642\n",
      "Epoch: 200, Average loss:      0.00035012\n",
      "Epoch: 240, Average loss:      0.00026914\n",
      "Epoch: 280, Average loss:      0.00021815\n",
      "Epoch: 320, Average loss:      0.00022041\n",
      "Epoch: 360, Average loss:      0.00021562\n",
      "Epoch: 400, Average loss:      0.00019677\n",
      "Epoch: 440, Average loss:      0.00020176\n",
      "Epoch: 480, Average loss:      0.00018795\n",
      "Epoch: 520, Average loss:      0.00020871\n",
      "Epoch: 560, Average loss:      0.00019712\n",
      "Epoch: 600, Average loss:      0.00019774\n",
      "Epoch: 640, Average loss:      0.00019856\n",
      "Epoch: 680, Average loss:      0.00019641\n",
      "Epoch: 720, Average loss:      0.00020730\n",
      "Epoch: 760, Average loss:      0.00019389\n",
      "Epoch: 800, Average loss:      0.00019704\n",
      "Epoch: 840, Average loss:      0.00019221\n",
      "Epoch: 880, Average loss:      0.00019619\n",
      "Epoch: 920, Average loss:      0.00018972\n",
      "Epoch: 960, Average loss:      0.00018538\n",
      "Epoch: 1000, Average loss:      0.00019230\n",
      "Epoch: 1040, Average loss:      0.00019262\n",
      "Epoch: 1080, Average loss:      0.00019992\n",
      "Epoch: 1120, Average loss:      0.00019222\n",
      "Epoch: 1160, Average loss:      0.00018882\n",
      "Epoch: 1200, Average loss:      0.00019054\n",
      "Epoch: 1240, Average loss:      0.00020026\n",
      "Epoch: 1280, Average loss:      0.00018506\n",
      "Epoch: 1320, Average loss:      0.00019756\n",
      "Epoch: 1360, Average loss:      0.00018868\n",
      "Epoch: 1400, Average loss:      0.00019709\n",
      "Epoch: 1440, Average loss:      0.00019694\n",
      "Epoch: 1480, Average loss:      0.00018623\n",
      "Epoch: 1520, Average loss:      0.00019614\n",
      "Epoch: 1560, Average loss:      0.00020601\n",
      "Epoch: 1600, Average loss:      0.00019367\n",
      "Epoch: 1640, Average loss:      0.00019768\n",
      "Epoch: 1680, Average loss:      0.00017986\n",
      "Epoch: 1720, Average loss:      0.00018976\n",
      "Epoch: 1760, Average loss:      0.00019381\n",
      "Epoch: 1800, Average loss:      0.00018984\n",
      "Epoch: 1840, Average loss:      0.00018753\n",
      "Epoch: 1880, Average loss:      0.00019373\n",
      "Epoch: 1920, Average loss:      0.00017789\n",
      "Epoch: 1960, Average loss:      0.00018741\n",
      "Orig train size =  193\n",
      "Epoch: 40, Average loss:      0.00100305\n",
      "Epoch: 80, Average loss:      0.00074710\n",
      "Epoch: 120, Average loss:      0.00089526\n",
      "Epoch: 160, Average loss:      0.00089788\n",
      "Epoch: 200, Average loss:      0.00091161\n",
      "Epoch: 240, Average loss:      0.00089288\n",
      "Epoch: 280, Average loss:      0.00086167\n",
      "Epoch: 320, Average loss:      0.00089550\n",
      "Epoch: 360, Average loss:      0.00087773\n",
      "Epoch: 400, Average loss:      0.00084825\n",
      "Epoch: 440, Average loss:      0.00084709\n",
      "Epoch: 480, Average loss:      0.00083549\n",
      "Epoch: 520, Average loss:      0.00091866\n",
      "Epoch: 560, Average loss:      0.00084522\n",
      "Epoch: 600, Average loss:      0.00082197\n",
      "Epoch: 640, Average loss:      0.00085383\n",
      "Epoch: 680, Average loss:      0.00083835\n",
      "Epoch: 720, Average loss:      0.00084690\n",
      "Epoch: 760, Average loss:      0.00089806\n",
      "Epoch: 800, Average loss:      0.00084573\n",
      "Epoch: 840, Average loss:      0.00071875\n",
      "Epoch: 880, Average loss:      0.00084427\n",
      "Epoch: 920, Average loss:      0.00085009\n",
      "Epoch: 960, Average loss:      0.00079898\n",
      "Epoch: 1000, Average loss:      0.00086942\n",
      "Epoch: 1040, Average loss:      0.00081494\n",
      "Epoch: 1080, Average loss:      0.00080692\n",
      "Epoch: 1120, Average loss:      0.00084492\n",
      "Epoch: 1160, Average loss:      0.00081996\n",
      "Epoch: 1200, Average loss:      0.00087192\n",
      "Epoch: 1240, Average loss:      0.00081098\n",
      "Epoch: 1280, Average loss:      0.00080322\n",
      "Epoch: 1320, Average loss:      0.00081092\n",
      "Epoch: 1360, Average loss:      0.00079882\n",
      "Epoch: 1400, Average loss:      0.00082432\n",
      "Epoch: 1440, Average loss:      0.00076436\n",
      "Epoch: 1480, Average loss:      0.00078683\n",
      "Epoch: 1520, Average loss:      0.00079925\n",
      "Epoch: 1560, Average loss:      0.00076840\n",
      "Epoch: 1600, Average loss:      0.00086808\n",
      "Epoch: 1640, Average loss:      0.00081947\n",
      "Epoch: 1680, Average loss:      0.00076500\n",
      "Epoch: 1720, Average loss:      0.00082245\n",
      "Epoch: 1760, Average loss:      0.00082223\n",
      "Epoch: 1800, Average loss:      0.00082206\n",
      "Epoch: 1840, Average loss:      0.00080947\n",
      "Epoch: 1880, Average loss:      0.00075862\n",
      "Epoch: 1920, Average loss:      0.00085092\n",
      "Epoch: 1960, Average loss:      0.00082525\n",
      "Orig train size =  193\n",
      "Epoch: 40, Average loss:      0.00037516\n",
      "Epoch: 80, Average loss:      0.00019465\n",
      "Epoch: 120, Average loss:      0.00016710\n",
      "Epoch: 160, Average loss:      0.00014351\n",
      "Epoch: 200, Average loss:      0.00011150\n",
      "Epoch: 240, Average loss:      0.00010357\n",
      "Epoch: 280, Average loss:      0.00008876\n",
      "Epoch: 320, Average loss:      0.00007264\n",
      "Epoch: 360, Average loss:      0.00008303\n",
      "Epoch: 400, Average loss:      0.00007436\n",
      "Epoch: 440, Average loss:      0.00006514\n",
      "Epoch: 480, Average loss:      0.00006351\n",
      "Epoch: 520, Average loss:      0.00005595\n",
      "Epoch: 560, Average loss:      0.00005715\n",
      "Epoch: 600, Average loss:      0.00005895\n",
      "Epoch: 640, Average loss:      0.00005628\n",
      "Epoch: 680, Average loss:      0.00006119\n",
      "Epoch: 720, Average loss:      0.00005121\n",
      "Epoch: 760, Average loss:      0.00005001\n",
      "Epoch: 800, Average loss:      0.00004293\n",
      "Epoch: 840, Average loss:      0.00005052\n",
      "Epoch: 880, Average loss:      0.00005128\n",
      "Epoch: 920, Average loss:      0.00004504\n",
      "Epoch: 960, Average loss:      0.00004279\n",
      "Epoch: 1000, Average loss:      0.00004570\n",
      "Epoch: 1040, Average loss:      0.00003886\n",
      "Epoch: 1080, Average loss:      0.00004001\n",
      "Epoch: 1120, Average loss:      0.00003816\n",
      "Epoch: 1160, Average loss:      0.00004114\n",
      "Epoch: 1200, Average loss:      0.00004091\n",
      "Epoch: 1240, Average loss:      0.00003900\n",
      "Epoch: 1280, Average loss:      0.00003887\n",
      "Epoch: 1320, Average loss:      0.00003900\n",
      "Epoch: 1360, Average loss:      0.00003630\n",
      "Epoch: 1400, Average loss:      0.00003372\n",
      "Epoch: 1440, Average loss:      0.00003756\n",
      "Epoch: 1480, Average loss:      0.00003549\n",
      "Epoch: 1520, Average loss:      0.00003622\n",
      "Epoch: 1560, Average loss:      0.00003327\n",
      "Epoch: 1600, Average loss:      0.00003625\n",
      "Epoch: 1640, Average loss:      0.00003760\n",
      "Epoch: 1680, Average loss:      0.00003743\n",
      "Epoch: 1720, Average loss:      0.00003264\n",
      "Epoch: 1760, Average loss:      0.00003286\n",
      "Epoch: 1800, Average loss:      0.00003111\n",
      "Epoch: 1840, Average loss:      0.00003345\n",
      "Epoch: 1880, Average loss:      0.00003041\n",
      "Epoch: 1920, Average loss:      0.00003176\n",
      "Epoch: 1960, Average loss:      0.00003067\n"
     ]
    }
   ],
   "source": [
    "l2_diff_tot_before = []\n",
    "l2_diff_tot_after = []\n",
    "for seed in np.arange(20):\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "    \n",
    "    model = FullModel()\n",
    "\n",
    "    x_train = x_train_orig\n",
    "    print(\"Orig train size = \", x_train.shape[0])\n",
    "    nsample = x_train.shape[0] - 1\n",
    "\n",
    "    y_train = func(x_train)\n",
    "    x_train_torch = torch.from_numpy(x_train).float()\n",
    "    y_train_torch = torch.from_numpy(y_train).float()\n",
    "    train_dataset = torch.utils.data.TensorDataset(x_train_torch, y_train_torch)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, shuffle=True)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.02)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(1, 2000):\n",
    "        train(model, optimizer, criterion, epoch)\n",
    "        \n",
    "    x_pred_np = np.arange(-2.5, 2.5001, 0.0001).reshape(-1, 1)\n",
    "    x_pred = torch.from_numpy(x_pred_np).float()\n",
    "    y_true = func(x_pred_np)\n",
    "    y_pred = model(x_pred)\n",
    "    x_np = x_pred.numpy().reshape(-1)\n",
    "    y_pred_np = y_pred.detach().numpy().reshape(-1)\n",
    "    y_true_np = y_true.reshape(-1)\n",
    "    l2_diff = avg_l2_diff(y_pred_np, y_true_np).astype(float)\n",
    "    l2_diff_tot_before.append(l2_diff)\n",
    "    \n",
    "    \n",
    "#     rng = np.random.default_rng(seed)\n",
    "#     res = np.empty([0])\n",
    "#     w = np.power(y_pred_np - y_true_np, 2)\n",
    "#     w = w / np.sum(w)\n",
    "#     sz = w.shape[0]\n",
    "#     freq = rng.multinomial(nsample, w)\n",
    "\n",
    "#     for i in range(sz):\n",
    "#         if freq[i]:\n",
    "#             res = np.concatenate((res, [x_np[i]]), axis=0)\n",
    "#     print(res)    \n",
    "    \n",
    "#     torch.manual_seed(seed)\n",
    "#     random.seed(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     torch.use_deterministic_algorithms(True)\n",
    "\n",
    "#     model = FullModel()\n",
    "#     x_train = x_train_orig\n",
    "#     x_train = np.concatenate((x_train, res), axis=0)\n",
    "#     print(\"After AL train size = \", x_train.shape[0])\n",
    "#     y_train = func(x_train)\n",
    "#     x_train_torch = torch.from_numpy(x_train).float()\n",
    "#     y_train_torch = torch.from_numpy(y_train).float()\n",
    "#     train_dataset = torch.utils.data.TensorDataset(x_train_torch, y_train_torch)\n",
    "#     train_loader = torch.utils.data.DataLoader(\n",
    "#         train_dataset, shuffle=True)\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=0.02)\n",
    "#     criterion = torch.nn.MSELoss()\n",
    "\n",
    "#     for epoch in range(1, 2000):\n",
    "#         train(model, optimizer, criterion, epoch)\n",
    "\n",
    "#     x_pred_np = np.arange(-2.5, 2.5001, 0.0001).reshape(-1, 1)\n",
    "#     x_pred = torch.from_numpy(x_pred_np).float() \n",
    "#     y_true = func(x_pred_np)\n",
    "#     y_pred = model(x_pred)\n",
    "#     x_np = x_pred.numpy().reshape(-1)\n",
    "#     y_pred_np = y_pred.detach().numpy().reshape(-1)\n",
    "#     y_true_np = y_true.reshape(-1)  \n",
    "#     l2_diff = avg_l2_diff(y_pred_np, y_true_np).astype(float)\n",
    "#     l2_diff_tot_after.append(l2_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aa66cb0-e8b1-44e1-8f32-bb91984c47f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.02670263093271e-05, 5.5010423303188614e-05, 0.0001624393785016679, 9.143436962650474e-05, 0.00024397209652918426, 0.00010891986862175248, 0.0002525390613661608, 0.0002326618576410996, 7.217395814373806e-05, 0.0001551015928568084, 0.00030466835706806247, 0.00017229983889778904, 0.0023069476985882447, 9.11318958189079e-05, 6.758135622609902e-05, 0.00025248165799039496, 8.727168496269771e-05, 0.0002712952309211347, 0.0011703754193346174, 9.060231588204366e-05]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(l2_diff_tot_before)\n",
    "print(l2_diff_tot_after)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_jupyter",
   "language": "python",
   "name": "base_jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
